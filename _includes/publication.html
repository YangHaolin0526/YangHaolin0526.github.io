<h1>Publication List</h1>
<p><b><u>Vision Language Model Training</u></b></p>
<p><b>2024</b></p>

<a href="">G-llava: Solving geometric problem with multi-modal large language model</a><br>
Jiahui Gao, Renjie Pi, Jipeng Zhang, Jiacheng Ye, Wanjun Zhong, Yufei Wang, Lanqing Hong, Jianhua Han, Hang Xu, Zhenguo Li, Lingpeng Kong.<br>
<i>ICLR 2024</i><br>
[<a href="javascript:copy(div3, bib3)">bib</a>]<br>
<div id="div3"></div><div id="bib3" style="display:none">
<div class="bib">
<pre>

</pre>
</div>
</div>
<br>


<a href="">Image Textualization: An Automatic Framework for Creating Accurate and Detailed Image Descriptions</a><br>
Renjie Pi, Jianshu Zhang, Jipeng Zhang, Rui Pan, Zhekai Chen, Tong Zhang.<br>
<i>NeurIPS 2024</i><br>
[<a href="javascript:copy(div4, bib4)">bib</a>]<br>
<div id="div4"></div><div id="bib4" style="display:none">
<div class="bib">
<pre>

</pre>
</div>
</div>
<br>
<p><b>2023</b></p>

<a href="">X2-VLM: All-In-One Pre-trained Model For Vision-Language Tasks</a><br>
Yan Zeng, Xinsong Zhang, Hang Li, Jiawei Wang, Jipeng Zhang, Wangchunshu Zhou.<br>
<i>TPAMI 2023</i><br>
[<a href="javascript:copy(div0, bib0)">bib</a>]<br>
<div id="div0"></div><div id="bib0" style="display:none">
<div class="bib">
<pre>

</pre>
</div>
</div>
<br>


<a href="">Toward Building General Foundation Models for Language, Vision, and Vision-Language Understanding Tasks</a><br>
Xinsong Zhang, Yan Zeng, Jipeng Zhang, Hang Li.<br>
<i>EMNLP 2023</i><br>
[<a href="javascript:copy(div1, bib1)">bib</a>]<br>
<div id="div1"></div><div id="bib1" style="display:none">
<div class="bib">
<pre>

</pre>
</div>
</div>
<br>


<a href="">UniMath: A Foundational and Multimodal Mathematical Reasoner</a><br>
Zhenwen Liang, Tianyu Yang, Jipeng Zhang, Xiangliang Zhang.<br>
<i>EMNLP 2023</i><br>
[<a href="javascript:copy(div2, bib2)">bib</a>]<br>
<div id="div2"></div><div id="bib2" style="display:none">
<div class="bib">
<pre>

</pre>
</div>
</div>
<br>
<p><b><u>Reinforcement Learning and Agent</u></b></p>
<p><b>2024</b></p>

<a href="">Mitigating the Alignment Tax of RLHF</a><br>
Yong Lin, Hangyu Lin, Wei Xiong, Shizhe Diao, Jianmeng Liu, Jipeng Zhang, Rui Pan, Haoxiang Wang, Wenbin Hu, Hanning Zhang, Hanze Dong, Renjie Pi, Han Zhao, Nan Jiang, Heng Ji, Yuan Yao, Tong Zhang.<br>
<i>EMNLP 2024</i><br>
[<a href="javascript:copy(div6, bib6)">bib</a>]<br>
<div id="div6"></div><div id="bib6" style="display:none">
<div class="bib">
<pre>

</pre>
</div>
</div>
<br>
<p><b>2023</b></p>

<a href="">Raft: Reward ranked finetuning for generative foundation model alignment</a><br>
Hanze Dong, Wei Xiong, Deepanshu Goyal, Rui Pan, Shizhe Diao, Jipeng Zhang, Kashun Shum, Tong Zhang.<br>
<i>TMLR 2023</i><br>
[<a href="javascript:copy(div5, bib5)">bib</a>]<br>
<div id="div5"></div><div id="bib5" style="display:none">
<div class="bib">
<pre>

</pre>
</div>
</div>
<br>
<p><b><u>Pretraining and Training Methods/Frameworks for LLMs/VLMs</u></b></p>
<p><b>2024</b></p>

<a href="">Fox Foundation Model: A Pioneering Small Language Model (SLM) for Cloud and Edge</a><br>
Zijian Hu*, Jipeng Zhang*, Rui Pan*, Zhaozhuo Xu, Shanshan Han, Han Jin, Alay Dilipbhai Shah, Dimitris Stripelis, Yuhang Yao, Salman Avestimehr, Chaoyang He, Tong Zhang.<br>
<i>arXiv 2024</i><br>
[<a href="javascript:copy(div7, bib7)">bib</a>]<br>
<div id="div7"></div><div id="bib7" style="display:none">
<div class="bib">
<pre>

</pre>
</div>
</div>
<br>
<p><b><u>LLM Data Techniques</u></b></p>
<p><b>2025</b></p>

<a href="">TAGCOS: Task-Agnostic Gradient Clustered Coreset Selection</a><br>
Jipeng zhang*, Yaxuan Qin*, Renjie Pi*, Weizhong Zhang, Rui Pan, Tong Zhang.<br>
<i>NAACL 2025</i><br>
[<a href="javascript:copy(div8, bib8)">bib</a>]<br>
<div id="div8"></div><div id="bib8" style="display:none">
<div class="bib">
<pre>

</pre>
</div>
</div>
<br>
<p><b><u>Reasoning</u></b></p>
<p><b>2024</b></p>

<a href="">TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts</a><br>
Ruida Wang*, Jipeng Zhang*, Yizhen Jia*, Rui Pan, Shizhe Diao, Renjie Pi, Tong Zhang.<br>
<i>EMNLP 2024</i><br>
[<a href="javascript:copy(div9, bib9)">bib</a>]<br>
<div id="div9"></div><div id="bib9" style="display:none">
<div class="bib">
<pre>

</pre>
</div>
</div>
<br>